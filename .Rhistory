plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=2, Sepal.Length=3))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=2, Sepal.Length=1))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=1))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=4))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=2, Sepal.Length=4))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=5, Sepal.Length=4))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=4))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2.2, Petal.Length=2.8))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2.2, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=3.6, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=3.5, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length)
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=3, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1, Petal.Length=3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1, Petal.Length=2))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1, Petal.Length=5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1, Petal.Length=4))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2, Petal.Length=4))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=4))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=3.5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=3.4))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=3.3))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=3.2))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=3.7))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=2.8))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=2.7))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=2.5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.9, Petal.Length=2.5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=2.5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=2.6))
# kernel에 따른 최적의 parameter 찾기
tune1 = tune.svm(Species~. ,data=train, gamma=10^(-5:0),cost = 10^(0:4), kernel="radial")
tune2 = tune.svm(Species~., data=train, cost=10^(0:4), kernel="linear")
tune3 = tune.svm(Species~., data=train, cost=10^(0:4), degree=2:4, kernel = "polynomia")
tune1 # gamma 0.0625 / cost 4
# kernel에 따른 최적의 parameter 찾기
tune1 = tune.svm(Species~. ,data=train, gamma=10^(-5:0),cost = 2^(0:4), kernel="radial")
tune2 = tune.svm(Species~., data=train, cost=2^(0:4), kernel="linear")
tune3 = tune.svm(Species~., data=train, cost=2^(0:4), degree=2:4, kernel = "polynomia")
tune1 # gamma 0.0625 / cost 4
tune2 # cost 8
tune3 # degree 3 / cost 16
# 찾은 최적값으로 모델 다시 만들기
model_1 = svm(Species~., data=train, kernel="radial", cost=2, gamma=0.1)
model_2 = svm(Species~., data=train, kernel="linear", cost=1)
model_3 = svm(Species~., data=train, kernel="polynomia", cost=8, degree=3)
# predict 해보기
pred_1 = predict(model_1, test)
pred_2 = predict(model_2, test)
pred_3 = predict(model_3, test)
# 정확도
confusionMatrix(pred_1, test$Species)
confusionMatrix(pred_2, test$Species)
confusionMatrix(pred_3, test$Species)
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=1.5, Petal.Length=2.6))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2.5, Petal.Length=2.6))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2.5, Petal.Length=3))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=4))
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=5))
# install.packages("e1071")
library("e1071")
str(iris)
# install.packages("e1071")
library("e1071")
str(iris)
# iris 데이터를 train과 test로 나눔
library(caret)
set.seed(100)
train_index = createDataPartition(y = iris$Species, p=0.7, list=FALSE)
train = iris[train_index,]
test = iris[-train_index,]
# 간단하게 SVM 모델 만들기
svm_model = svm(Species~., data=train)
summary(svm_model)
# predict 해보기
pred = predict(svm_model,test)
table(real=test$Species ,predict=pred)
confusionMatrix(pred, test$Species)
# predict 해보기
pred = predict(svm_model,test)
confusionMatrix(pred, test$Species)
# kernel에 따른 최적의 parameter 찾기
tune1 = tune.svm(Species~. ,data=train, gamma=10^(-5:0),cost = 2^(0:4), kernel="radial")
tune2 = tune.svm(Species~., data=train, cost=2^(0:4), kernel="linear")
tune3 = tune.svm(Species~., data=train, cost=2^(0:4), degree=2:4, kernel = "polynomia")
tune1 # gamma 0.1 / cost 2
tune2 # cost 1
tune3 # degree 3 / cost 8
# 찾은 최적값으로 모델 다시 만들기
model_1 = svm(Species~., data=train, kernel="radial", cost=2, gamma=0.1)
summary(model_1)
model_2 = svm(Species~., data=train, kernel="linear", cost=1)
summary(model_2)
model_3 = svm(Species~., data=train, kernel="polynomia", cost=8, degree=3)
summary(model_3)
# 찾은 최적값으로 모델 다시 만들기
model_1 = svm(Species~., data=train, kernel="radial", cost=2, gamma=0.1)
summary(model_1)
# 찾은 최적값으로 모델 다시 만들기
model_1 = svm(Species~., data=train, kernel="radial", cost=2, gamma=0.5)
summary(model_1)
# 찾은 최적값으로 모델 다시 만들기
model_1 = svm(Species~., data=train, kernel="radial", cost=2, gamma=0.1)
summary(model_1)
# 서포트벡터 확인(몇 번째 관찰값이 서포트 벡터일까!)
model_1$index
model_2$index
model_3$index
# predict 해보기
pred_1 = predict(model_1, test)
pred_2 = predict(model_2, test)
pred_3 = predict(model_3, test)
# 정확도
confusionMatrix(pred_1, test$Species)
confusionMatrix(pred_2, test$Species)
confusionMatrix(pred_3, test$Species)
# 시각화
plot(model_3, train, Petal.Width~ Petal.Length,
slice = list(Sepal.Width=3, Sepal.Length=5))
plot(model_3, train, Sepal.Width~ Sepal.Length,
slice = list(Petal.Width=2.5, Petal.Length=3))
def.par = par(no.readonly = TRUE) # 다양한 옵션 가능도록 TRUE
#install.packages("MVA")
library(MVA)
# USairpollution
head(USairpollution)
# 연구 주제! 제조기업들의 숫자
mlab = "Manufacturing enterprises with 20 or more workers"
# 천단위 인구수
plab = "Population size (1970 census) in thousands"
# 연속형 이변량 자료를 나타내는 표준적인 방법
plot(popul~ manu, data=USairpollution, xlab=mlab, ylab = plab)
# 옵션을 더 사용하면 효율적으로 표현 가능
plot(popul~ manu, data=USairpollution, xlab=mlab, ylab = plab,
pch = 19, col="blue", cex = 1.2, col.lab = "purple", font.lab=2,
fg = gray(0.7), bg=gray(0.2), cex.axis = 1.5, cex.lab = 1.1)
rug(USairpollution$popul, side=1)
rug(USairpollution$manu, side=2)
# 각 변수의 히스토그램과 상자그림을 산점도와 함께 보는 방법
par(mar=c(1,1,1,1))
layout(matrix(c(2,0,1,3), nrow=2, byrow=T), widths = c(2,1), heights=c(1,2),
respect=T)
# put the second picture in (1,1), put the first picture in (2,1),
# put the third one in (2,2)
# in the divided region (2 by 2) where the first col is twide sider than the second col,
layout.show(3)
# layout 설정한 후에 그려보자
xlim = with(USairpollution, range(manu)) * 1.1
plot(popul~manu, data=USairpollution, cex.lab = 0.9,
xlab = mlab, ylab = plab, type="n", xlim = xlim) # type = "n": no1
# drawing
with(USairpollution, text(manu, popul, cex = 0.6, labels =
abbreviate(row.names(USairpollution))))
with(USairpollution, hist(manu, main="", xlim=xlim))
with(USairpollution, boxplot(popul))
# 일변량 상자그림의 2차원적 확장
par(mfrow=c(1,1))
lab.city = c("Chicago", "Detroit","Cleveland","Philadelphia")
outcity = match(lab.city, rownames(USairpollution))
x = USairpollution[,c("manu","popul")]
bvbox(x, mtitle="", xlab=mlab, ylab=plab, cex=1.2, cex.axis=1.5, cex.lab=1.1)
text(x$manu[outcity], x$popul[outcity], labels=lab.city, cex=1.5, pos=
c(2,2,4,2,2))
# 상관관계 정확하게~
cor(x)
with(USairpollution, cor(manu[-outcity], popul[-outcity]))
# 블록집합( convex hull): 모든 자료가 그 안에 있거나 그 위에 있는 최소 볼록다변체
hull = with(USairpollution, chull(manu, popul))
hull
with(USairpollution, plot(manu, popul, pch=1, xlab=mlab, ylab=plab))
with(USairpollution, polygon(manu[hull], popul[hull], density=15, angle=50, col="pink"))
# 이상치 제거 with convex hull
with(USairpollution, cor(manu[-hull], popul[-hull]))
# 산점도 행렬 (전체적인 이해) 변수 사이의 모든 가능한 산점도
pairs(USairpollution, pch=".", cex=1.5)
ylim.wind = with(USairpollution, range(wind)) * c(0.95, 1)
plot(wind~temp, data=USairpollution,
xlab="Average annual temperature(Fahrenheit)",
ylab = "Average annual wind speed(m.p.h)",
pch=10, ylim = ylim.wind, col="darkblue",
cex.axis=1.5, cex.lab=1.1)
with(USairpollution, symbols(temp, wind, circles=SO2, inches=0.5, add=T, fg="darkgreen"))
# 별그림
# 산점도에 세 개 이상의 변수들을 표현하는 방법
# 각각의 그룹에 대해서 지역에 속해있는 정보를 워차트를 이요해 그리는 것!
palette(rainbow(12, s=0.6, v=0.75))
stars(USairpollution, draw.segments = T, key.loc=c(20,0), nrow=5)
plot(wind~temp, data=USairpollution, xlab="Average annual temperature(Fahrenheit)",
ylab = "Average annual wind speed(m.n.h)", pch=10, ylim=ylim.wind, col="darkblue",
cex.axis=1.5, cex.lab=1.1)
with(USairpollution, stars(USairpollution[,-c(2,5)], locations=cbind(temp, wind),
label=NULL, add=T))
# 별그림
# 산점도에 세 개 이상의 변수들을 표현하는 방법
# 각각의 그룹에 대해서 지역에 속해있는 정보를 워차트를 이요해 그리는 것!
palette(rainbow(12, s=0.6, v=0.75))
stars(USairpollution, draw.segments = T, key.loc=c(20,0), nrow=5)
plot(wind~temp, data=USairpollution, xlab="Average annual temperature(Fahrenheit)",
ylab = "Average annual wind speed(m.n.h)", pch=10, ylim=ylim.wind, col="darkblue",
cex.axis=1.5, cex.lab=1.1)
with(USairpollution, stars(USairpollution[,-c(2,5)], locations=cbind(temp, wind),
label=NULL, add=T))
# 별그림
# 산점도에 세 개 이상의 변수들을 표현하는 방법
# 각각의 그룹에 대해서 지역에 속해있는 정보를 워차트를 이요해 그리는 것!
palette(rainbow(12, s=0.6, v=0.75))
stars(USairpollution, draw.segments = T, key.loc=c(20,0), nrow=5)
plot(wind~temp, data=USairpollution, xlab="Average annual temperature(Fahrenheit)",
ylab = "Average annual wind speed(m.n.h)", pch=10, ylim=ylim.wind, col="darkblue",
cex.axis=1.5, cex.lab=1.1)
with(USairpollution, stars(USairpollution[,-c(2,5)], locations=cbind(temp, wind),
label=NULL, add=T))
library(ade4)
data(olympic)
data<-olympic$tab
summary(data)
data$"100"<-max(data$'100') - data$'100'
data$'400'<-max(data$'400') - data$'400'
data$'110'<-max(data$'110') - data$'110'
data$'1500'<-max(data$'1500') - data$'1500'
cor(data)
pca.cor = princomp(data,cor=T, scores=T)
pca.cor$loadings
# 주성분 계수의 차이가 있다.
# 이유는 데이터를 centering 했냐 안했냐에 따라 달라지기 때문이다. cov의 경우 분산이 큰 1500달리기가 압도적으로 큰 비중을 차지하는 것을 볼 수 있다. 하지만 cor의 경우 골고루 분산된 것을 볼 수 있다.
summary(pca.cor)
screeplot(pca.cor, type="l", pch=19, main="screeplot")
# 4로 할래 이유는 3과 4가 비슷하고 5로가면 또 다시 떨어지므로 3과 4까지 포함하면 충분히 설명 가능하다고 생각
summary(pca.cor)
screeplot(pca.cor, type="l", pch=19, main="screeplot")
# 4로 할래 이유는 3과 4가 비슷하고 5로가면 또 다시 떨어지므로 3과 4까지 포함하면 충분히 설명 가능하다고 생각
def.par = par(no.readonly = TRUE) # 다양한 옵션 가능도록 TRUE
#install.packages("MVA")
library(MVA)
# USairpollution
head(USairpollution)
# 연구 주제! 제조기업들의 숫자
mlab = "Manufacturing enterprises with 20 or more workers"
# 천단위 인구수
plab = "Population size (1970 census) in thousands"
# 연속형 이변량 자료를 나타내는 표준적인 방법
plot(popul~ manu, data=USairpollution, xlab=mlab, ylab = plab)
(5-8)^2
((5-8)^2+(2+1)^2+(1-4)^2)*(1/3)
((5-14)^2+(2-8)^2+(1-13)^2)*(1/3)
9+87
1.2*60+81
-ln(0.79)
-log(0.79)
-log(0.70)
-log(0.80)
1.2*60+81
((5-8)^2+(2+1)^2+(1-4)^2)*(1/3)
((5-14)^2+(2-8)^2+(1-13)^2)*(1/3)
9+87
corr = matrix(c(1,0.3,0.3,1),nrow=2)
corr
ev = eigen(corr)
ev$values
ev$vectors
### 1-3
```{r}
```
## 2번
### 2-1
### 2-2
### parallel 패키지
library(parallel)
# 코어 개수 획득
numCores = parallel::detectCores() -1
numCores
# 클러스터 초기화 -> 백엔드 결과 추가하기 (작업관리자)
myCluster = parallel::makeCluster(numCores)
# 클러스터 초기화 -> 백엔드 결과 추가하기 (작업관리자)
myCluster = parallel::makeCluster(numCores)
# 클러스터 중지
parallel::stopCluster(myCluster)
# CPU 병렬처리
parallel::parLapply(cl=myCluster, X=2:4, fun=function(x) {2^x})
# CPU 병렬처리
parallel::parLapply(cl=myCluster, X=2:4, fun=function(x) {2^X})
# CPU 병렬처리
parallel::parLapply(cl=myCluster, X=2:4, fun=function(X) {2^X})
# 클러스터 초기화 -> 백엔드 결과 추가하기 (작업관리자)
myCluster = parallel::makeCluster(numCores)
# CPU 병렬처리
parallel::parLapply(cl=myCluster, X=2:4, fun=function(X) {2^X})
# CPU 병렬처리
parallel::parLapply(cl=myCluster, X=2:4, fun=function(X) {2^X})
# CPU 병렬처리
parallel::parLapply(cl=myCluster, X=2:4, fun=function(X) {2^X})
# 클러스터 중지
parallel::stopCluster(myCluster)
## 병렬처리실습
myCluster = parallel::makeCluster(numCores)
setwd("C:/Users/danan/Desktop/Bitamin/BITA4_Machine-Learning-with-R")
iseq = seq(1,10000,1)
parLapply(myCluster, iseq, function(y){
write(y, "progress.txt", append=T)
})
# 클러스터 중지
parallel::stopCluster(myCluster)
## 병렬처리실습
myCluster = parallel::makeCluster(numCores)
setwd("C:/Users/danan/Desktop/Bitamin/BITA4_Machine-Learning-with-R")
iseq = seq(1,10000,1)
parLapply(myCluster, iseq, function(y){
write(y, "progress.txt", append=T)
})
# 클러스터 중지
parallel::stopCluster(myCluster)
# 클러스터 초기화
myCluster = parallel::makeCluster(numCores)
parallel::clusterExport(myCluster, "base")
# 변수 등록
base = 2
parallel::clusterExport(myCluster, "base")
# CPU 병렬처리
parallel::parLapply(cl=myCluster,
X = 2:4,
fun=function(x){
base^X
})
### foreach 패키지
library(foreach)
library(doParallel)
# 코어 개수 획득
numCores = parallel::detectCores() -1
# 클러스터 초기화
myCluster = parallel::makeCluster(numCores)
doParallel::registerDoParallel(myCluster)
parallel::clusterExport(myCluster,"base")
# CPU 병렬처리, C는 cbind 느낌
foreach::foreach(exponent = 2:4, combine=C) %dopar%{
base^exponent
}
# CPU 병렬처리, C는 cbind 느낌
foreach::foreach(exponent = 2:4, combine=c) %dopar%{
base^exponent
}
## foreach() 함수를 별도의 외부 함수로 정의할 경우 오류가 나므로 외부변수를
# 사용하는데 있어 불편함을 해소하기 위하여 export 옵션 제공
test = function(exponent){
foreach::foreach(exponent = 2:4,
.combine = c,
.export = "base") %dopar% {
base^exponent
}
}
test()
# 클러스터 초기화
myCluster = parallel::makeCluster(numCores)
doParallel::registerDoParallel(myCluster)
folds = createFolds(iris$Sepal.Length, k=3)
library(caret)
set.seed(1234)
folds = createFolds(iris$Sepal.Length, k=3)
td_tmp = foreach::foreach(k=1:3,
.combine = rbind,
.packages = c("dplyr","broom","caret"),
.inorder = TRUE) %dopar% {
tmp = iris[-unlist(folds[k]),] %>% group_by(Species) %>%
do(fit = lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data=.))
tidy(tmp,fit)
}
# 클러스터 중지
parallel::stopCluster(myCluster)
#########
# 코어 개수 획득
numCores = parallel::detectCores() -1
# 클러스터 초기화
myCluster = parallel::makeCluster(numCores, type = "PSOCK")
# CPU 병렬처리
foreach(x=list(1,2,"a")) %dopar% {
tryCatch({
c(1/x,x,2^x)
}, error=function(e) {
return(paste0("The variable '",x,"'"," caused the error: ",e,"'"))
})
}
#########
# 코어 개수 획득
numCores = parallel::detectCores() -1
# 클러스터 초기화
myCluster = parallel::makeCluster(numCores, type = "PSOCK")
# CPU 병렬처리
foreach(x=list(1,2,"a")) %dopar% {
tryCatch({
c(1/x,x,2^x)
}, error=function(e) {
return(paste0("The variable '",x,"'"," caused the error: ",e,"'"))
})
}
# 클러스터 초기화
myCluster = parallel::makeCluster(numCores, type = "PSOCK")
# CPU 병렬처리
foreach(X=list(1,2,"a")) %dopar% {
tryCatch({
c(1/X,X,2^X)
}, error=function(e) {
return(paste0("The variable '",X,"'"," caused the error: ",e,"'"))
})
}
# 클러스터 중지
parallel::stopCluster(myCluster)
system.time({for(i in 1:10000){
i+5
}})
n_core = detectCores()
cl = makeCluster(n_core-1)
registerDoParallel(cl)
system.time(
{foreach(i = 1:10000) %dopar%{
i+5
}}
)
################ h2o 실습 - 데이터 준비 ############
library(dplyr)
library(caret)
flights_data = readRDS("C:/Users/danan/Desktop/Bitamin/BITA4_Machine-Learning-with-R/flights.RDS")
head(flights_data)
str(flights_data)
flights_data$target = ifelse((is.na(flights_data$dep_delay) | (flights_data$dep_delay<=30 & flights_data$dep_delay >= -30)) &
(is.na(flights_data$arr_delay) | (flights_data$arr_delay <=30 & flights_data$arr_delay >= -30)), "normal","delay")
table(flights_data$target)
# 모델링을 위해 일부 변수만 사용 및 categorical 변수 factor로 변경
final_data = flights_data %>%  select("month","carrier","flight","dest","air_time","distance","target")
str(final_data)
final_Data$carrier = as.factor(final_data$carrier)
final_data$carrier = as.factor(final_data$carrier)
final_data$dest = as.factor(final_data$dest)
final_data$target = as.factor(final_data$target)
## train, test 나누기
set.seed(1234)
train_idx = createDataPartition(final_data$target, p=0.7, list=F)
test = final_data[-train_idx, ]
train = final_data[train_idx, ]
set.seed(1234)
train_idx = createDataPartition(final_data$target, p=0.7, list=F)
train = final_data[train_idx, ]
test = final_data[-train_idx, ]
install.packages("h2o")
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk-13.0.1")
h2o.init(nthreads = 15, max_mem_size = "10g")
library(h2o)
Sys.setenv(JAVA_HOME="C:/Program Files/Java/jdk-13.0.1")
h2o.init(nthreads = 15, max_mem_size = "10g")
test_data_h2o = as.h2o(test, destination_frame = "test_data_h2o")
train_data_h2o = as.h2o(train, destination_frame = "train_data_h2o")
target = "target"
features = names(train)[!names(train) %in% target]
target ; featrures
target ; features
rf_model = h2o.randomForest(x = features, y=target, training_frame = train_data_h2o,
model_id = "rf_model", ntrees = 500, seed=1234, mtries = floor(ncol(train) / 3), verbose=F)
######################## R에서 메일 보내기 Naver ###########################
library(mailR)
install.packages("mailR")
